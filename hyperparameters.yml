cartpole1:
  env_id: CartPole-v1
  replay_memory_size: 100000
  mini_batch_size: 64
  epsilon_init: 1
  epsilon_decay: 0.9995
  epsilon_min: 0.01
  network_sync_rate: 100
  learning_rate_a: 0.001
  discount_factor_g: 0.99
  stop_on_reward: 100000
  fc1_nodes: 128
  enable_double_dqn: False
  enable_dueling_dqn: True

#flappybird dqn  
flappybird1:
  env_id: FlappyBird-v0
  replay_memory_size: 100000
  mini_batch_size: 64
  epsilon_init: 1
  epsilon_decay: 0.99_99_5
  epsilon_min: 0.05
  network_sync_rate: 128
  learning_rate_a: 0.0001
  discount_factor_g: 0.99
  stop_on_reward: 100000
  fc1_nodes: 512
  hidden_dim: 128
  env_make_params:
    use_lidar: False
  enable_double_dqn: False
  enable_dueling_dqn: False
  training_episodes: 1000000

#flappybird ppo

ppo_flappybird:
  env_id: FlappyBird-v0
  num_envs: 4              
  clip_coef: 0.2           
  vf_coef: 0.5             
  ent_coef: 0.01           
  lr: 0.0002                
  max_grad_norm: 0.5       
  update_epochs: 4         
  num_minibatches: 4       
  state_dim: 12
  action_dim: 2
  layer_size: 128          
  total_epochs: 2000     
  device: "cpu"            
  num_steps: 256           
  gamma: 0.99              
  gae_lambda: 0.95         


  #CNN encoder
  frame_stack: 4             
  input_channels: 4          
  conv_channels: [32, 64, 64]
  kernel_sizes: [8, 4, 3]    
  strides: [4, 2, 1]         
  paddings: [0, 0, 0]       
  hidden_size: 512          
  activation: "relu"         
  normalize_obs: true        
  grayscale: true           
  frame_skip: 1              

# dqn_flappybird:
#   env_id: FlappyBird-v0



#flappybird policy_gradient
policy_gradient_flappybird:
  env_id: FlappyBird-v0