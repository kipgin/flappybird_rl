cartpole1:
  env_id: CartPole-v1
  replay_memory_size: 100000
  mini_batch_size: 64
  epsilon_init: 1
  epsilon_decay: 0.9995
  epsilon_min: 0.01
  network_sync_rate: 100
  learning_rate_a: 0.001
  discount_factor_g: 0.99
  stop_on_reward: 100000
  fc1_nodes: 128
  enable_double_dqn: False
  enable_dueling_dqn: True

#flappybird dqn  
flappybird1:
  env_id: FlappyBird-v0
  replay_memory_size: 100000
  mini_batch_size: 512
  num_envs : 8
  total_timesteps: 5000000
  learning_starts: 20000
  train_freq: 1
  gradient_steps: 1

  use_per : False
  per_alpha : 0.6
  per_beta : 0.4
  per_eps : 1e-6


  epsilon_init: 1
  epsilon_decay: 0.99995
  epsilon_min: 0.05
  network_sync_rate: 1000
  learning_rate_a: 0.0001
  discount_factor_g: 0.99
  stop_on_reward: 100000
  fc1_nodes: 512
  hidden_dim: 128
  env_make_params:
    use_lidar: False
  enable_double_dqn: False
  enable_dueling_dqn: False
  training_episodes: 1000000

  #CNN encoder
  frame_stack: 4             
  input_channels: 4          
  conv_channels: [32, 64, 64]
  kernel_sizes: [8, 4, 3]    
  strides: [4, 2, 1]         
  paddings: [0, 0, 0]       
  hidden_size: 512          
  activation: "relu"         
  normalize_obs: true        
  grayscale: true           
  frame_skip: 4
        

#flappybird ppo

ppo_flappybird:
  env_id: FlappyBird-v0
  seed : 42
  num_envs: 8            
  clip_coef: 0.2           
  vf_coef: 0.5             
  ent_coef: 0.02         
  lr: 0.0002                
  max_grad_norm: 0.5       
  update_epochs: 4         
  num_minibatches: 4
  # mini_batch_size: 512 
  update_epochs: 4
  state_dim: 12
  action_dim: 2
  layer_size: 128          
  total_epochs: 6000000                
  num_steps: 512
  anneal_lr: True           
  gamma: 0.99              
  gae_lambda: 0.95         
  #CNN encoder
  frame_stack: 4             
  input_channels: 4          
  conv_channels: [32, 64, 64]
  kernel_sizes: [8, 4, 3]    
  strides: [4, 2, 1]         
  paddings: [0, 0, 0]       
  hidden_size: 512          
  activation: "relu"         
  normalize_obs: true        
  grayscale: true           
  frame_skip: 2
  env_make_params:
    use_lidar: False          

# dqn_flappybird:
#   env_id: FlappyBird-v0



#flappybird policy_gradient
policy_gradient_flappybird:
  env_id: FlappyBird-v0
  seed : 42
  num_envs: 8                 
  vf_coef: 0.5             
  ent_coef: 0.01        
  lr: 0.0001               
  max_grad_norm: 0.5       
  update_epochs: 1         
  num_minibatches: 1      
  state_dim: 12
  action_dim: 2
  hidden_dim: 128          
  total_epochs: 6000000
  use_baseline : True
  
  num_steps: 512 
  gamma: 0.99              
  gae_lambda: 0.95         
  #CNN encoder
  frame_stack: 4             
  input_channels: 4          
  conv_channels: [32, 64, 64]
  kernel_sizes: [8, 4, 3]    
  strides: [4, 2, 1]         
  paddings: [0, 0, 0]       
  hidden_size: 512          
  activation: "relu"         
  normalize_obs: true        
  grayscale: true           
  frame_skip: 4
  env_make_params:
    use_lidar: False

#flappybird dqn  
dueling_dqn:
  env_id: FlappyBird-v0
  replay_memory_size: 100000
  mini_batch_size: 512
  num_envs : 8
  epsilon_init: 1
  epsilon_decay: 0.995
  epsilon_min: 0.05
  network_sync_rate: 64
  learning_rate_a: 0.0001
  discount_factor_g: 0.99
  stop_on_reward: 100000
  fc1_nodes: 512
  hidden_dim: 128
  env_make_params:
    use_lidar: False
  enable_double_dqn: True
  enable_dueling_dqn: True
  training_episodes: 1000000
  #CNN encoder
  frame_stack: 4             
  input_channels: 4          
  conv_channels: [32, 64, 64]
  kernel_sizes: [8, 4, 3]    
  strides: [4, 2, 1]         
  paddings: [0, 0, 0]       
  hidden_size: 512          
  activation: "relu"         
  normalize_obs: true        
  grayscale: true           
  frame_skip: 4